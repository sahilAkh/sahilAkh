{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7682dca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 22) (2069158853.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 22\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 22)\n"
     ]
    }
   ],
   "source": [
    "# Gaussian discriminant analysis in 2d\n",
    "# Author: Duane Rich, heavily modified by Kevin Murphy\n",
    "# Based on matlab code by Kevin Murphy\n",
    "# https://github.com/probml/pmtk3/blob/master/demos/discrimAnalysisDboundariesDemo.m\n",
    "\n",
    "try:\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq scikit-learn\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "figdir = \"Python progs\"\n",
    "\"\n",
    "figdir = \"Users\\Sahil\\Desktop\\Python progs\"\n",
    "\n",
    "\n",
    "def savefig(fname):\n",
    "    plt.savefig(os.path.join(figdir, fname))\n",
    "\n",
    "def mvn2d(x, y, u, sigma):\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    xy = np.c_[xx.ravel(), yy.ravel()]\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    z = np.dot((xy - u), sigma_inv)\n",
    "    z = np.sum(z * (xy - u), axis=1)\n",
    "    z = np.exp(-0.5 * z)\n",
    "    z = z / (2 * np.pi * np.linalg.det(sigma) ** 0.5)\n",
    "    return z.reshape(xx.shape)\n",
    "\n",
    "\n",
    "# Each model specifies the means and covariances.\n",
    "# If the covariances are equal across classes, dboundarioes\n",
    "# will be linear even if we use QDA\n",
    "\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "\n",
    "Sigma1 = np.array([[4, 1], [1, 2]])\n",
    "Sigma2 = np.array([[2, 0], [0, 1]])\n",
    "Sigma3 = np.eye(2)\n",
    "\n",
    "mus = [[0, 0], [0, 4], [4, 4]]\n",
    "sigmas = [Sigma1, Sigma2, Sigma3]\n",
    "# model = ([[0, 0], [0, 4], [4, 4]], [Sigma1, Sigma2, Sigma3])\n",
    "\n",
    "ngrid = 200\n",
    "n_samples = 30  # 300  # number of each class samples\n",
    "model_names = (\"LDA\", \"QDA\")\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def make_data(mu, sigma):\n",
    "    # generate random points\n",
    "    x = []  # store sample points\n",
    "    labels = []  # store class labels\n",
    "    nclasses = len(mu)  # means\n",
    "    for i in range(nclasses):\n",
    "        x.append(np.random.multivariate_normal(mu[i], sigma[i], n_samples))\n",
    "        labels.append([i] * n_samples)\n",
    "    return x, labels\n",
    "\n",
    "\n",
    "def make_grid(x):\n",
    "    points = np.vstack(x)\n",
    "    x_min, y_min = np.min(points, axis=0)\n",
    "    x_max, y_max = np.max(points, axis=0)\n",
    "    x_range = np.linspace(x_min - 1, x_max + 1, ngrid)\n",
    "    y_range = np.linspace(y_min - 1, y_max + 1, ngrid)\n",
    "    xx, yy = np.meshgrid(x_range, y_range)\n",
    "    return xx, yy, x_range, y_range\n",
    "\n",
    "\n",
    "def plot_dboundaries(xx, yy, z, z_p):\n",
    "    plt.pcolormesh(xx, yy, z, alpha=0.1)\n",
    "    plt.jet()\n",
    "    nclasses = z_p.shape[1]\n",
    "    for j in range(nclasses):\n",
    "        plt.contour(xx, yy, z_p[:, j].reshape(ngrid, ngrid), [0.5], lw=3, colors=\"k\")\n",
    "\n",
    "\n",
    "def plot_points(x):\n",
    "    c = \"bgr\"\n",
    "    m = \"xos\"\n",
    "    for i, point in enumerate(x):\n",
    "        N = point.shape[0]\n",
    "        nplot = min(N, 30)\n",
    "        plt.plot(point[:nplot, 0], point[:nplot, 1], c[i] + m[i])\n",
    "\n",
    "\n",
    "def plot_contours(xx, yy, x_range, y_range, u, sigma):\n",
    "    nclasses = len(u)\n",
    "    c = \"bgr\"\n",
    "    m = \"xos\"\n",
    "    for i in range(nclasses):\n",
    "        prob = mvn2d(x_range, y_range, u[i], sigma[i])\n",
    "        cs = plt.contour(xx, yy, prob, colors=c[i])\n",
    "\n",
    "\n",
    "def make_one_hot(yhat):\n",
    "    yy = yhat.reshape(-1, 1)  # make 2d\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    Y = enc.fit_transform(yy)\n",
    "    return Y\n",
    "\n",
    "x, labels = make_data(mus, sigmas)\n",
    "xx, yy, x_range, y_range = make_grid(x)\n",
    "X = np.vstack(x)\n",
    "Y = np.hstack(labels)\n",
    "\n",
    "plt.figure()\n",
    "plot_points(x)\n",
    "plt.axis(\"square\")\n",
    "plt.tight_layout()\n",
    "savefig(\"gda_2d_data.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_points(x)\n",
    "plot_contours(xx, yy, x_range, y_range, mus, sigmas)\n",
    "plt.axis(\"square\")\n",
    "plt.tight_layout()\n",
    "savefig(\"gda_2d_contours.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e264bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted exam results: [1 0 1 0 0]\n",
      "[[5.  ]\n",
      " [0.75]\n",
      " [5.5 ]\n",
      " [2.25]\n",
      " [2.75]] [1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Hours studied and exam results (pass=1, fail=0)\n",
    "hours_studied = np.array([0.5, 0.75, 1, 1.25, 1.5, 1.75, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4, 4.25, 4.5, 4.75, 5, 5.5]).reshape(-1, 1)\n",
    "passed_exam = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hours_studied, passed_exam, test_size=0.25, random_state=0)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Predicted exam results:\", y_pred)\n",
    "print(X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
